{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Convolutional Neural Networks(CNN) MODEL - ELIRAM AND PROSPER\n### ByClass dataset\n### The full complement of the NIST Special Database 19 is available in the ByClass split. This dataset have the same image information but differ in the number of images in each class. The dataset have an uneven number of images per class and there are more digits than letters. The number of letters roughly equate to the frequency of use in the English language.\n### train: 697,932\n### test: 116,323\n### total: 814,255\n### classes: ByClass 62 (unbalanced)\n## Obtain accuracy: 86,9 %","metadata":{}},{"cell_type":"code","source":"# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"execution":{"iopub.status.busy":"2021-11-11T11:29:03.254067Z","iopub.execute_input":"2021-11-11T11:29:03.25441Z","iopub.status.idle":"2021-11-11T11:29:03.306102Z","shell.execute_reply.started":"2021-11-11T11:29:03.254323Z","shell.execute_reply":"2021-11-11T11:29:03.305294Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Libraries and Data Import","metadata":{}},{"cell_type":"code","source":"!pip install python-mnist","metadata":{"execution":{"iopub.status.busy":"2021-11-11T11:29:03.307365Z","iopub.execute_input":"2021-11-11T11:29:03.307711Z","iopub.status.idle":"2021-11-11T11:29:14.254406Z","shell.execute_reply.started":"2021-11-11T11:29:03.307681Z","shell.execute_reply":"2021-11-11T11:29:14.253632Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nfrom mnist.loader import MNIST\n\nemndata = MNIST('input')\n#This will load the train and test data\nX_train, y_train = emndata.load('../input/emnist/emnist_source_files/emnist-byclass-train-images-idx3-ubyte',\n                               '../input/emnist/emnist_source_files/emnist-byclass-train-labels-idx1-ubyte')\nX_test, y_test = emndata.load('../input/emnist/emnist_source_files/emnist-byclass-test-images-idx3-ubyte',\n                             '../input/emnist/emnist_source_files/emnist-byclass-test-labels-idx1-ubyte')\n\n# We Convert data to numpy arrays and normalize images to the interval [0, 1] for normalization\nX_train = np.array(X_train) / 255.0\ny_train = np.array(y_train)\nX_test = np.array(X_test) / 255.0\ny_test = np.array(y_test)","metadata":{"execution":{"iopub.status.busy":"2021-11-11T11:29:14.255972Z","iopub.execute_input":"2021-11-11T11:29:14.256224Z","iopub.status.idle":"2021-11-11T11:32:25.76504Z","shell.execute_reply.started":"2021-11-11T11:29:14.256193Z","shell.execute_reply":"2021-11-11T11:32:25.76384Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Checking the shape of our data\nX_train.shape, y_train.shape, X_test.shape, y_test.shape","metadata":{"execution":{"iopub.status.busy":"2021-11-11T11:32:25.766571Z","iopub.execute_input":"2021-11-11T11:32:25.766809Z","iopub.status.idle":"2021-11-11T11:32:25.774994Z","shell.execute_reply.started":"2021-11-11T11:32:25.766778Z","shell.execute_reply":"2021-11-11T11:32:25.774124Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Getting Data ready for pre-processing","metadata":{}},{"cell_type":"code","source":"#Reshaping all images into 28*28*1 \nX_train = X_train.reshape(X_train.shape[0], 28, 28, 1)\nX_test = X_test.reshape(X_test.shape[0], 28, 28, 1)","metadata":{"execution":{"iopub.status.busy":"2021-11-11T11:32:25.77715Z","iopub.execute_input":"2021-11-11T11:32:25.777903Z","iopub.status.idle":"2021-11-11T11:32:25.788527Z","shell.execute_reply.started":"2021-11-11T11:32:25.777853Z","shell.execute_reply":"2021-11-11T11:32:25.787492Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Checking the new shape\nX_train.shape, X_test.shape","metadata":{"execution":{"iopub.status.busy":"2021-11-11T11:32:25.791152Z","iopub.execute_input":"2021-11-11T11:32:25.791708Z","iopub.status.idle":"2021-11-11T11:32:25.802863Z","shell.execute_reply.started":"2021-11-11T11:32:25.791662Z","shell.execute_reply":"2021-11-11T11:32:25.801892Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from matplotlib import pyplot as plt\n#Display a random image\nplt.imshow(X_train[0])\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-11-11T11:32:25.804702Z","iopub.execute_input":"2021-11-11T11:32:25.805029Z","iopub.status.idle":"2021-11-11T11:32:26.056392Z","shell.execute_reply.started":"2021-11-11T11:32:25.804987Z","shell.execute_reply":"2021-11-11T11:32:26.055474Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Creation of model","metadata":{}},{"cell_type":"code","source":"from keras.models import Sequential\nfrom keras import optimizers\nfrom keras.layers import Convolution2D, MaxPooling2D, Dropout, Flatten, Dense, Reshape\nfrom keras import backend as K\nfrom keras.constraints import maxnorm\nfrom keras.utils import np_utils\n\n# Converting train images and test images values into float\ntrain_images = X_train.astype('float32')\ntest_images = X_test.astype('float32')\n\n# One hot encoding\ntrain_labels = np_utils.to_categorical(y_train, 62)\ntest_labels = np_utils.to_categorical(y_test, 62)","metadata":{"execution":{"iopub.status.busy":"2021-11-11T11:32:26.057811Z","iopub.execute_input":"2021-11-11T11:32:26.058126Z","iopub.status.idle":"2021-11-11T11:32:32.923802Z","shell.execute_reply.started":"2021-11-11T11:32:26.058084Z","shell.execute_reply":"2021-11-11T11:32:32.923014Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Spliting our dataframes to train(train_images, train_labels) and validation(X_valid, y_valid) subsets\n# We will use the validation subset(X_valid, y_valid) for our final predictions\nfrom sklearn.model_selection import train_test_split\ntrain_images, X_valid, train_labels, y_valid = train_test_split(train_images, train_labels, test_size=.25, random_state=2)","metadata":{"execution":{"iopub.status.busy":"2021-11-11T11:32:32.925005Z","iopub.execute_input":"2021-11-11T11:32:32.925379Z","iopub.status.idle":"2021-11-11T11:32:34.257274Z","shell.execute_reply.started":"2021-11-11T11:32:32.925349Z","shell.execute_reply":"2021-11-11T11:32:34.256558Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Overview of subsets shapes\ntrain_images.shape, train_labels.shape, test_images.shape, test_labels.shape, X_valid.shape, y_valid.shape","metadata":{"execution":{"iopub.status.busy":"2021-11-11T11:32:34.258415Z","iopub.execute_input":"2021-11-11T11:32:34.258811Z","iopub.status.idle":"2021-11-11T11:32:34.265444Z","shell.execute_reply.started":"2021-11-11T11:32:34.25878Z","shell.execute_reply":"2021-11-11T11:32:34.264393Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# CNN Model building ","metadata":{}},{"cell_type":"code","source":"# Set the CNN model \n# Our CNN architechture is In -> [[Conv2D->relu]*2 -> MaxPool2D -> Dropout]*2 -> Flatten -> Dense -> Dropout -> Out\n\nmodel = Sequential()\n\nmodel.add(Convolution2D(32, (5,5), input_shape=(28,28,1),\n                             activation='relu',padding='same',\n                            kernel_constraint=maxnorm(3)))\nmodel.add(Convolution2D(32, (5,5), input_shape=(28,28,1),\n                             activation='relu',\n                            kernel_constraint=maxnorm(3)))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Convolution2D(64, (3,3), input_shape=(28,28,1),\n                             activation='relu',padding='same',\n                            kernel_constraint=maxnorm(3)))\nmodel.add(Convolution2D(64, (3,3), input_shape=(28,28,1),\n                             activation='relu',\n                            kernel_constraint=maxnorm(3)))\nmodel.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Flatten())\nmodel.add(Dense(256, activation='relu', kernel_constraint=maxnorm(3)))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(62, activation='softmax'))\n\nmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2021-11-11T11:32:34.268265Z","iopub.execute_input":"2021-11-11T11:32:34.268508Z","iopub.status.idle":"2021-11-11T11:32:34.66318Z","shell.execute_reply.started":"2021-11-11T11:32:34.268455Z","shell.execute_reply":"2021-11-11T11:32:34.662224Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Training of model and evaluation","metadata":{}},{"cell_type":"code","source":"# history = model.fit(train_images,train_labels,validation_data=(test_images, test_labels), \n#                         batch_size=128, epochs=5)","metadata":{"execution":{"iopub.status.busy":"2021-11-11T11:32:34.666299Z","iopub.execute_input":"2021-11-11T11:32:34.666561Z","iopub.status.idle":"2021-11-11T11:32:34.670557Z","shell.execute_reply.started":"2021-11-11T11:32:34.666526Z","shell.execute_reply":"2021-11-11T11:32:34.66951Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # Evaluating model on test data. \n# scores = model.evaluate(test_images,test_labels, verbose = 0)\n# print(\"Accuracy: %.2f%%\"%(scores[1]*100))","metadata":{"execution":{"iopub.status.busy":"2021-11-11T11:32:34.672078Z","iopub.execute_input":"2021-11-11T11:32:34.672396Z","iopub.status.idle":"2021-11-11T11:32:34.682291Z","shell.execute_reply.started":"2021-11-11T11:32:34.672354Z","shell.execute_reply":"2021-11-11T11:32:34.681595Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Creating model history graphs","metadata":{}},{"cell_type":"code","source":"# from matplotlib import pyplot as plt\n# print(history.history.keys())\n# # summarize history for accuracy\n# plt.plot(history.history['accuracy'])\n# plt.plot(history.history['val_accuracy'])\n# plt.title('Model Accuracy')\n# plt.ylabel('Accuracy')\n# plt.xlabel('Epoch')\n# plt.legend(['Train', 'Test'], loc='upper left')\n# plt.grid()\n# plt.show()\n# # summarize history for loss\n# plt.plot(history.history['loss'])\n# plt.plot(history.history['val_loss'])\n# plt.title('Model loss')\n# plt.ylabel('Loss')\n# plt.xlabel('Epoch')\n# plt.legend(['Train', 'Test'], loc='upper left')\n# plt.grid()\n# plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-11-11T11:32:34.683436Z","iopub.execute_input":"2021-11-11T11:32:34.683759Z","iopub.status.idle":"2021-11-11T11:32:34.694063Z","shell.execute_reply.started":"2021-11-11T11:32:34.683718Z","shell.execute_reply":"2021-11-11T11:32:34.693453Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Predicting a single image using the model","metadata":{}},{"cell_type":"code","source":"# Load the model \nfrom keras.models import load_model\nfrom keras.models import model_from_json\n\njson_file = open('../input/ml-emnist-recognition-project-model-save/model.json', 'r')\nloaded_model_json = json_file.read()\njson_file.close()\nloaded_model = model_from_json(loaded_model_json)\n\nloaded_model.load_weights('../input/ml-emnist-recognition-project-model-save/model.h5')\n\nmodel = loaded_model\nprint('Model successfully loaded')\n\nmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n\n#Showing the model accuracy\nscores = model.evaluate(test_images,test_labels, verbose = 0)\nprint(\"Accuracy: %.2f%%\"%(scores[1]*100))","metadata":{"execution":{"iopub.status.busy":"2021-11-11T11:32:34.694855Z","iopub.execute_input":"2021-11-11T11:32:34.695055Z","iopub.status.idle":"2021-11-11T11:33:28.043985Z","shell.execute_reply.started":"2021-11-11T11:32:34.695029Z","shell.execute_reply":"2021-11-11T11:33:28.042066Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Creating of a dictionary that maps indexes to the labels\nimport pandas as pd\n\nlabel_map = pd.read_csv(\"../input/emnist/emnist-byclass-mapping.txt\", delimiter = ' ', index_col=0,header=None, squeeze=True)\nlabel_dict = {}\nfor index, label in enumerate(label_map):\n    label_dict[index] = chr(label)\n \nlabel_dict","metadata":{"execution":{"iopub.status.busy":"2021-11-11T11:33:28.045361Z","iopub.execute_input":"2021-11-11T11:33:28.045619Z","iopub.status.idle":"2021-11-11T11:33:28.089941Z","shell.execute_reply.started":"2021-11-11T11:33:28.045589Z","shell.execute_reply":"2021-11-11T11:33:28.089099Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create a function to make an image prediction \n\ndef make_prediction(image_index, sample_dataset, label_map):\n    prediction = model.predict(sample_dataset[image_index].reshape(-1,28,28,1))\n    predicted_label = np.argmax(prediction)\n    return label_map[predicted_label]\n\n# Predict the 6738th element\nprediction = make_prediction(6738, X_valid, label_dict)\n\n# Print our prediction\nprint(\"The predicted caracter is: \", prediction)\n\n\n# Showing the real 6738th image character\nchar = X_valid[6738].reshape(28,28)\nplt.imshow(char)\nplt.show","metadata":{"execution":{"iopub.status.busy":"2021-11-11T11:33:28.091546Z","iopub.execute_input":"2021-11-11T11:33:28.092204Z","iopub.status.idle":"2021-11-11T11:33:28.481625Z","shell.execute_reply.started":"2021-11-11T11:33:28.092154Z","shell.execute_reply":"2021-11-11T11:33:28.48075Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Saving the model","metadata":{}},{"cell_type":"code","source":"# from keras.models import load_model\n# from keras.models import model_from_json\n\n# #saves the model info as json file\n# model_json = model.to_json()\n# with open(\"model.json\", \"w\") as json_file:\n#     json_file.write(model_json)\n \n\n# # Creates a HDF5 file 'model.h5'\n# model.save_weights(\"model.h5\")\n# print(\"Saved model to disk\")","metadata":{"execution":{"iopub.status.busy":"2021-11-11T11:33:28.482834Z","iopub.execute_input":"2021-11-11T11:33:28.483082Z","iopub.status.idle":"2021-11-11T11:33:28.487094Z","shell.execute_reply.started":"2021-11-11T11:33:28.483053Z","shell.execute_reply":"2021-11-11T11:33:28.486233Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Loading the model","metadata":{}},{"cell_type":"code","source":"# from keras.models import load_model\n# from keras.models import model_from_json\n\n# json_file = open('../input/ml-emnist-recognition-project-model-save/model.json', 'r')\n# loaded_model_json = json_file.read()\n# json_file.close()\n# loaded_model = model_from_json(loaded_model_json)\n\n# loaded_model.load_weights('../input/ml-emnist-recognition-project-model-save/model.h5')\n\n# model = loaded_model\n# print('Model successfully loaded')\n\n# model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2021-11-11T11:33:28.488299Z","iopub.execute_input":"2021-11-11T11:33:28.48857Z","iopub.status.idle":"2021-11-11T11:33:28.500092Z","shell.execute_reply.started":"2021-11-11T11:33:28.488529Z","shell.execute_reply":"2021-11-11T11:33:28.499016Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# #evaluating model on test data. will take time\n# scores = model.evaluate(test_images,test_labels, verbose = 0)\n# print(\"Accuracy: %.2f%%\"%(scores[1]*100))","metadata":{"execution":{"iopub.status.busy":"2021-11-11T11:33:28.501589Z","iopub.execute_input":"2021-11-11T11:33:28.501867Z","iopub.status.idle":"2021-11-11T11:33:28.511497Z","shell.execute_reply.started":"2021-11-11T11:33:28.501838Z","shell.execute_reply":"2021-11-11T11:33:28.510824Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}